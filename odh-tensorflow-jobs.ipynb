{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training data and upload them to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   162  100   162    0     0    247      0 --:--:-- --:--:-- --:--:--   247\n",
      "\r",
      " 48 4959k   48 2383k    0     0  1453k      0  0:00:03  0:00:01  0:00:02 1453k\r",
      "100 4959k  100 4959k    0     0  2227k      0  0:00:02  0:00:02 --:--:-- 4396k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -O -L https://github.com/vpavlin/odh-tensorflow-jobs/raw/master/training/num-dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket ODH-TENSORFLOW-JOBS-DEMO created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx00000000000000041a545-005c1261a6-11ed1491-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-request-id': 'tx00000000000000041a545-005c1261a6-11ed1491-default',\n",
       "   'content-type': 'application/xml',\n",
       "   'content-length': '641',\n",
       "   'date': 'Thu, 13 Dec 2018 13:41:58 GMT',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': '/input-data/num-dataset.tar.gz',\n",
       "   'LastModified': datetime.datetime(2018, 12, 13, 13, 41, 58, 78000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"938fb559ed093232ca5e985d1f370bf9\"',\n",
       "   'Size': 5078688,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': 'Datahub Insights Dev User',\n",
       "    'ID': 'datahub-insights1-dev'}}],\n",
       " 'Name': 'ODH-TENSORFLOW-JOBS-DEMO',\n",
       " 'Prefix': '/input-data/num-dataset.tar.gz',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bucket=\"ODH-TENSORFLOW-JOBS-DEMO\"\n",
    "\n",
    "import boto3, os\n",
    "conn = boto3.client(service_name='s3',\n",
    "    endpoint_url=os.environ['S3_ENDPOINT_URL'])\n",
    "\n",
    "buckets = [ b['Name'] for b in conn.list_buckets()['Buckets']]\n",
    "if my_bucket not in buckets:\n",
    "    resp = conn.create_bucket(Bucket=my_bucket)\n",
    "    if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "        raise Exception(\"Could not create bucket:(\")\n",
    "        \n",
    "    print(\"Bucket %s created\" % my_bucket)\n",
    "else:\n",
    "    print(\"Bucket %s exists\" % my_bucket)\n",
    "    \n",
    "key = \"/input-data/num-dataset.tar.gz\"\n",
    "conn.upload_file(Bucket=my_bucket, Key=key, Filename=\"num-dataset.tar.gz\")\n",
    "conn.list_objects(Bucket=my_bucket, Prefix=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install OpenShift client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   654    0   654    0     0   1807      0 --:--:-- --:--:-- --:--:--  1811\n",
      "\r",
      "  0 53.8M    0 16360    0     0  16785      0  0:56:06 --:--:--  0:56:06 16785\r",
      " 23 53.8M   23 12.8M    0     0  6693k      0  0:00:08  0:00:01  0:00:07 12.9M\r",
      " 36 53.8M   36 19.7M    0     0  6838k      0  0:00:08  0:00:02  0:00:06  9.9M\r",
      " 43 53.8M   43 23.2M    0     0  5992k      0  0:00:09  0:00:03  0:00:06 7937k\r",
      " 48 53.8M   48 26.2M    0     0  5412k      0  0:00:10  0:00:04  0:00:06 6726k\r",
      " 57 53.8M   57 30.8M    0     0  5210k      0  0:00:10  0:00:06  0:00:04 6206k\r",
      " 62 53.8M   62 33.5M    0     0  4790k      0  0:00:11  0:00:07  0:00:04 4068k\r",
      " 63 53.8M   63 34.2M    0     0  4402k      0  0:00:12  0:00:07  0:00:05 2960k\r",
      " 66 53.8M   66 35.7M    0     0  4081k      0  0:00:13  0:00:08  0:00:05 2567k\r",
      " 69 53.8M   69 37.6M    0     0  3873k      0  0:00:14  0:00:09  0:00:05 2339k\r",
      " 74 53.8M   74 40.1M    0     0  3741k      0  0:00:14  0:00:10  0:00:04 1928k\r",
      " 78 53.8M   78 42.1M    0     0  3610k      0  0:00:15  0:00:11  0:00:04 1850k\r",
      " 81 53.8M   81 44.0M    0     0  3480k      0  0:00:15  0:00:12  0:00:03 2013k\r",
      " 87 53.8M   87 47.4M    0     0  3473k      0  0:00:15  0:00:13  0:00:02 2384k\r",
      " 98 53.8M   98 52.9M    0     0  3625k      0  0:00:15  0:00:14  0:00:01 3131k\r",
      "100 53.8M  100 53.8M    0     0  3658k      0  0:00:15  0:00:15 --:--:-- 3436k\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -o oc.tar.gz -L https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz\n",
    "tar xzf oc.tar.gz\n",
    "cp openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit/oc ~/../bin/oc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:serviceaccount:vpavlin-jupyterhub:jupyter-tensorflow\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List templates\n",
    "\n",
    "You should see templates imported from [odh-tensorflow-jobs](https://github.com/vpavlin/odh-tensorflow-jobs/tree/master/openshift) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                    DESCRIPTION                                                                        PARAMETERS    OBJECTS\n",
      "jupyter-notebook-workspace-tensorflow   Template for deploying Tensorflow enable Jupyter Notebook images with persist...   4 (all set)   7\n",
      "odh-config                              Template to configure basic components of ODH ML flow                              3 (2 blank)   1\n",
      "odh-tensorflow-serving                  Template to serve models using tensorflow                                          5 (all set)   2\n",
      "odh-tensorflow-training                 Template to train models using tensorflow                                          9 (all set)   1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List parameters for the training template\n",
    "\n",
    "`oc process` command allows you to list configurable parameters for a given template. We'll look at the training job tempalte first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    DESCRIPTION                                                                                              GENERATOR           VALUE\n",
      "APP_NAME                Short name of your application (to be used in OpenShift artifact names)                                                      demo\n",
      "TRAINING_STEPS          Number of training steps to perform                                                                                          10000\n",
      "INPUT_DATA_LOCATION     Location of input data in form of 's3://BUCKET/path/', path is used as prefix to lookup the data in S3                       s3://MY-BUCKET/data/\n",
      "OUTPUT_MODEL_LOCATION   Location where the resulting model will be stored                                                                            s3://MY-BUCKET/model-out/\n",
      "MEMORY                  Memory limit to be assigned to the job                                                                                       2Gi\n",
      "CPU                     Limit for number of cores to assign to the job                                                                               2\n",
      "GIT_REPO                Repository to build from                                                                                                     https://github.com/vpavlin/odh-tensorflow-jobs\n",
      "CONTEXT_DIR             Directory inside the git repository to use as root                                                                           training\n",
      "RUN_FILE                A file containing code doing the training                                                                                    app.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-training --parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the training job\n",
    "\n",
    "Configure all necessary parameters from above and pipe the `oc process` output to `oc apply` command to submit the job to OpenShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch/odh-tensorflow-training-from-jupyter created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-training \\\n",
    "    -p APP_NAME=from-jupyter \\\n",
    "    -p TRAINING_STEPS=2000 \\\n",
    "    -p INPUT_DATA_LOCATION=\"s3://ODH-TENSORFLOW-JOBS-DEMO/input-data\" \\\n",
    "    -p OUTPUT_MODEL_LOCATION=\"s3://ODH-TENSORFLOW-JOBS-DEMO/output-model\" \\\n",
    "    -p MEMORY=\"9Gi\" \\\n",
    "    -p CPU=\"9\" \\\n",
    "        | oc apply -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View logs\n",
    "\n",
    "You can review the job execution by (re)running the below `oc logs` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'app_code'...\n",
      "Using context dir training\n",
      "Processing /opt/app-root/src/app_code/pyodh\n",
      "Collecting git+https://github.com/CermakM/intect (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/CermakM/intect to /tmp/pip-m1f4ugh7-build\n",
      "Requirement already satisfied: tensorflow==1.10.0 in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.6/site-packages (from pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Collecting names (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/44/4e/f9cb7ef2df0250f4ba3334fbdabaa94f9c88097089763d8e85ada8092f84/names-0.3.0.tar.gz (789kB)\n",
      "Collecting pyyaml (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting matplotlib (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc logs job.batch/odh-tensorflow-training-from-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'app_code'...\n",
      "Using context dir training\n",
      "Processing /opt/app-root/src/app_code/pyodh\n",
      "Collecting git+https://github.com/CermakM/intect (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/CermakM/intect to /tmp/pip-m1f4ugh7-build\n",
      "Requirement already satisfied: tensorflow==1.10.0 in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.6/site-packages (from pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Collecting names (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/44/4e/f9cb7ef2df0250f4ba3334fbdabaa94f9c88097089763d8e85ada8092f84/names-0.3.0.tar.gz (789kB)\n",
      "Collecting pyyaml (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting matplotlib (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "Collecting scipy (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "Collecting pillow (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "Collecting scikit-image (from intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/90/553120309c53bdfca25c9c50769ae40a538a90c24db8c082468aec898d00/scikit_image-0.14.1-cp36-cp36m-manylinux1_x86_64.whl (25.3MB)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/app-root/lib/python3.6/site-packages (from tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.51 in /opt/app-root/lib/python3.6/site-packages (from boto3->pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/app-root/lib/python3.6/site-packages (from boto3->pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/app-root/lib/python3.6/site-packages (from boto3->pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e8/6777f6624681c8b9701a8a0a5654f3eb56919a01a78e12bf3c73f5a3c714/pyparsing-2.3.0-py2.py3-none-any.whl (59kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3->-r requirements.txt (line 3))\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/68/74a8527b3a727aa69736baaf5a273d83947fa6c91ef4f2e1efddda00d8b6/PyWavelets-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\n",
      "Collecting dask[array]>=0.9.0 (from scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/e5/6407c2349622699eab0881e6bc6e978b8da67872a105e5e20b72ff190c65/dask-1.0.0-py2.py3-none-any.whl (685kB)\n",
      "Collecting cloudpickle>=0.2.1 (from scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/87/7b7ef3038b4783911e3fdecb5c566e3a817ce3e890e164fc174c088edb1e/cloudpickle-0.6.1-py2.py3-none-any.whl\n",
      "Collecting networkx>=1.8 (from scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20; python_version >= \"3.4\" in /opt/app-root/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.51->boto3->pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/app-root/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.51->boto3->pyodh==0.0.1->-r requirements.txt (line 2))\n",
      "Collecting toolz>=0.7.3; extra == \"array\" (from dask[array]>=0.9.0->scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/d0/a73c15bbeda3d2e7b381a36afb0d9cd770a9f4adc5d1532691013ba881db/toolz-0.9.0.tar.gz (45kB)\n",
      "Collecting decorator>=4.3.0 (from networkx>=1.8->scikit-image->intect==0.2.3->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pyodh, names, pyyaml, pyparsing, cycler, kiwisolver, matplotlib, scipy, pillow, PyWavelets, toolz, dask, cloudpickle, decorator, networkx, scikit-image, intect\n",
      "  Running setup.py install for pyodh: started\n",
      "    Running setup.py install for pyodh: finished with status 'done'\n",
      "  Running setup.py install for names: started\n",
      "    Running setup.py install for names: finished with status 'done'\n",
      "  Running setup.py install for pyyaml: started\n",
      "    Running setup.py install for pyyaml: finished with status 'done'\n",
      "  Running setup.py install for toolz: started\n",
      "    Running setup.py install for toolz: finished with status 'done'\n",
      "  Running setup.py install for networkx: started\n",
      "    Running setup.py install for networkx: finished with status 'done'\n",
      "  Running setup.py install for intect: started\n",
      "    Running setup.py install for intect: finished with status 'done'\n",
      "Successfully installed PyWavelets-1.0.1 cloudpickle-0.6.1 cycler-0.10.0 dask-1.0.0 decorator-4.3.0 intect-0.2.3 kiwisolver-1.0.1 matplotlib-3.0.2 names-0.3.0 networkx-2.2 pillow-5.3.0 pyodh-0.0.1 pyparsing-2.3.0 pyyaml-3.13 scikit-image-0.14.1 scipy-1.1.0 toolz-0.9.0\n",
      "You are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Running python app.py\n",
      "Downloading /tmp/data/num-dataset.tar.gz from /input-data/num-dataset.tar.gz\n",
      "Found 7280 images belonging to 10 classes.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '.model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f86acc9e400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Training the architecture: `numbers`\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f86acca25c0>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-13 13:43:46.991836: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into .model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1/model.ckpt.\n",
      "INFO:tensorflow:accuracy = 0.0625, learning_rate = 0.005, loss = 2.3029056\n",
      "INFO:tensorflow:loss = 2.3029056, step = 1\n",
      "INFO:tensorflow:global_step/sec: 22.0673\n",
      "INFO:tensorflow:accuracy = 0.359375, learning_rate = 0.004963846, loss = 1.8188462 (4.532 sec)\n",
      "INFO:tensorflow:loss = 1.8188462, step = 101 (4.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.772\n",
      "INFO:tensorflow:accuracy = 0.5416667, learning_rate = 0.0049279532, loss = 1.554636 (4.391 sec)\n",
      "INFO:tensorflow:loss = 1.554636, step = 201 (4.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2584\n",
      "INFO:tensorflow:accuracy = 0.65625, learning_rate = 0.0048923204, loss = 1.4772618 (4.299 sec)\n",
      "INFO:tensorflow:loss = 1.4772618, step = 301 (4.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5898\n",
      "INFO:tensorflow:accuracy = 0.725, learning_rate = 0.004856945, loss = 1.4732952 (4.632 sec)\n",
      "INFO:tensorflow:loss = 1.4732952, step = 401 (4.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9445\n",
      "INFO:tensorflow:accuracy = 0.765625, learning_rate = 0.0048218253, loss = 1.4889992 (4.358 sec)\n",
      "INFO:tensorflow:loss = 1.4889992, step = 501 (4.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2219\n",
      "INFO:tensorflow:accuracy = 0.79910713, learning_rate = 0.00478696, loss = 1.4626923 (4.500 sec)\n",
      "INFO:tensorflow:loss = 1.4626923, step = 601 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7362\n",
      "INFO:tensorflow:accuracy = 0.82421875, learning_rate = 0.0047523463, loss = 1.4637672 (4.399 sec)\n",
      "INFO:tensorflow:loss = 1.4637672, step = 701 (4.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1812\n",
      "INFO:tensorflow:accuracy = 0.84375, learning_rate = 0.004717983, loss = 1.4616205 (4.313 sec)\n",
      "INFO:tensorflow:loss = 1.4616205, step = 801 (4.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8058\n",
      "INFO:tensorflow:accuracy = 0.859375, learning_rate = 0.004683868, loss = 1.4633458 (4.586 sec)\n",
      "INFO:tensorflow:loss = 1.4633458, step = 901 (4.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5627\n",
      "INFO:tensorflow:accuracy = 0.87215906, learning_rate = 0.00465, loss = 1.4620177 (4.432 sec)\n",
      "INFO:tensorflow:loss = 1.4620177, step = 1001 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1703\n",
      "INFO:tensorflow:accuracy = 0.8828125, learning_rate = 0.0046163765, loss = 1.464143 (4.316 sec)\n",
      "INFO:tensorflow:loss = 1.464143, step = 1101 (4.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2213\n",
      "INFO:tensorflow:accuracy = 0.8918269, learning_rate = 0.0045829965, loss = 1.4620708 (4.500 sec)\n",
      "INFO:tensorflow:loss = 1.4620708, step = 1201 (4.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2991\n",
      "INFO:tensorflow:accuracy = 0.8995536, learning_rate = 0.0045498577, loss = 1.4617773 (4.485 sec)\n",
      "INFO:tensorflow:loss = 1.4617773, step = 1301 (4.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3944\n",
      "INFO:tensorflow:accuracy = 0.90625, learning_rate = 0.0045169587, loss = 1.4612724 (4.466 sec)\n",
      "INFO:tensorflow:loss = 1.4612724, step = 1401 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4595\n",
      "INFO:tensorflow:accuracy = 0.9121094, learning_rate = 0.0044842977, loss = 1.4613521 (4.453 sec)\n",
      "INFO:tensorflow:loss = 1.4613521, step = 1501 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2484\n",
      "INFO:tensorflow:accuracy = 0.9172794, learning_rate = 0.004451873, loss = 1.4612498 (4.494 sec)\n",
      "INFO:tensorflow:loss = 1.4612498, step = 1601 (4.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8799\n",
      "INFO:tensorflow:accuracy = 0.921875, learning_rate = 0.004419682, loss = 1.4613612 (4.371 sec)\n",
      "INFO:tensorflow:loss = 1.4613612, step = 1701 (4.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1239\n",
      "INFO:tensorflow:accuracy = 0.9259868, learning_rate = 0.004387724, loss = 1.4612246 (4.324 sec)\n",
      "INFO:tensorflow:loss = 1.4612246, step = 1801 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7605\n",
      "INFO:tensorflow:accuracy = 0.9296875, learning_rate = 0.0043559973, loss = 1.4611987 (4.596 sec)\n",
      "INFO:tensorflow:loss = 1.4611987, step = 1901 (4.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9305\n",
      "INFO:tensorflow:accuracy = 0.93303573, learning_rate = 0.0043245, loss = 1.4613525 (4.560 sec)\n",
      "INFO:tensorflow:loss = 1.4613525, step = 2001 (4.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7224\n",
      "INFO:tensorflow:accuracy = 0.93607956, learning_rate = 0.0042932304, loss = 1.461206 (4.401 sec)\n",
      "INFO:tensorflow:loss = 1.461206, step = 2101 (4.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0422\n",
      "INFO:tensorflow:accuracy = 0.9388587, learning_rate = 0.0042621866, loss = 1.461224 (4.340 sec)\n",
      "INFO:tensorflow:loss = 1.461224, step = 2201 (4.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2270 into .model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4611838.\n",
      "INFO:tensorflow:Training took: 108.59116649627686 s.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7f86acd19a58>\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-13-13:45:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from .model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1/model.ckpt-2270\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoint for embeddings for global step: 0\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-13-13:45:36\n",
      "INFO:tensorflow:Saving dict for global step 2270: accuracy = 1.0, global_step = 2270, loss = 1.4612117\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2270: .model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1/model.ckpt-2270\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'confidence', 'classes', 'scores']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 32, 32, 1) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from .model_cache/numbers,lr=0.005,bs=32,conv=2,fcl=1/model.ckpt-2270\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./model_out/temp-b'1544708736'/saved_model.pb\n",
      "Model has been exported to `b'./model_out/1544708736'`\n",
      "Creating gzipped tar model_out.tgz from ./model_out\n",
      "File model_out.tgz uploaded\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc logs job.batch/odh-tensorflow-training-from-jupyter -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List parameters for Tensorflow serving template\n",
    "\n",
    "Once the training job is completed, we can deploy the serving endpoint - see the parametrs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   DESCRIPTION                                                               GENERATOR           VALUE\n",
      "APP_NAME               Short name of your application (to be used in OpenShift artifact names)                       demo\n",
      "INPUT_MODEL_LOCATION   Location where the resulting model will be stored                                             s3://MY-BUCKET/model-out/\n",
      "MODEL_NAME             Name of the model                                                                             mnist\n",
      "MEMORY                 Memory limit to be assigned to the job                                                        1Gi\n",
      "CPU                    Limit for number of cores to assign to the job                                                1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-serving --parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Tensorflow serving endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploymentconfig.apps.openshift.io/odh-tensorflow-serving-from-jupyter created\n",
      "service/odh-tensorflow-serving-from-jupyter created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-serving \\\n",
    "    -p APP_NAME=from-jupyter \\\n",
    "    -p INPUT_MODEL_LOCATION=\"s3://ODH-TENSORFLOW-JOBS-DEMO/output-model\" \\\n",
    "    -p MODEL_NAME=\"intect\" \\\n",
    "        | oc apply -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Scaling odh-tensorflow-serving-from-jupyter-1 to 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc logs deploymentconfig.apps.openshift.io/odh-tensorflow-serving-from-jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the predictions\n",
    "\n",
    "As the training job uses [intect]() tool, we can use `intect-client` to call to our model server. Run the following cell to install the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/CermakM/intect\n",
      "  Cloning https://github.com/CermakM/intect to /tmp/pip-req-build-wrtfln65\n",
      "Requirement already satisfied (use --upgrade to upgrade): intect==0.2.3 from git+https://github.com/CermakM/intect in /opt/app-root/lib/python3.6/site-packages\n",
      "Requirement already satisfied: names in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (0.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (3.13)\n",
      "Requirement already satisfied: matplotlib in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (2.0.2)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (1.15.4)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (0.19.1)\n",
      "Requirement already satisfied: pillow in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (5.3.0)\n",
      "Requirement already satisfied: scikit-image in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (0.13.1)\n",
      "Requirement already satisfied: tensorflow in /opt/app-root/lib/python3.6/site-packages (from intect==0.2.3) (1.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3) (1.11.0)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3) (2018.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3) (2.7.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->intect==0.2.3) (2.3.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/app-root/lib/python3.6/site-packages (from scikit-image->intect==0.2.3) (1.0.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /opt/app-root/lib/python3.6/site-packages (from scikit-image->intect==0.2.3) (2.2)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (3.6.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (1.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (0.32.3)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (39.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (1.16.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (0.6.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->intect==0.2.3) (0.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/app-root/lib/python3.6/site-packages (from networkx>=1.8->scikit-image->intect==0.2.3) (4.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow->intect==0.2.3) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow->intect==0.2.3) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install git+https://github.com/CermakM/intect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling prediction endpoint\n",
    "\n",
    "We need to configure the server name - you can see the name of the deployed service above as `service/odh-tensorflow-serving-from-jupyter` - we'll use the part after slash. The model name needs to match the name defined in `MODEL_NAME` parameter above.\n",
    "\n",
    "You can use [2.png](https://github.com/vpavlin/odh-tensorflow-jobs/blob/master/2.png) to test the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   140  100   140    0     0    423      0 --:--:-- --:--:-- --:--:--   424\n",
      "\r",
      "100  1867  100  1867    0     0   3327      0 --:--:-- --:--:-- --:--:--  3327\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -O -L https://github.com/vpavlin/odh-tensorflow-jobs/raw/master/2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloaded image \n",
    "\n",
    "![2.png](2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs {\n",
      "  key: \"output\"\n",
      "  value {\n",
      "    dtype: DT_STRING\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "    string_val: \"2\"\n",
      "  }\n",
      "}\n",
      "model_spec {\n",
      "  name: \"intect\"\n",
      "  version {\n",
      "    value: 1544708736\n",
      "  }\n",
      "  signature_name: \"prediction\"\n",
      "}\n",
      "\n",
      "outputs {\n",
      "  key: \"output\"\n",
      "  value {\n",
      "    dtype: DT_FLOAT\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "    float_val: 0.9730215072631836\n",
      "  }\n",
      "}\n",
      "model_spec {\n",
      "  name: \"intect\"\n",
      "  version {\n",
      "    value: 1544708736\n",
      "  }\n",
      "  signature_name: \"confidence\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib/python3.6/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/opt/app-root/lib/python3.6/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "intect-client --host odh-tensorflow-serving-from-jupyter --port 6006 --model_name intect --images 2.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
