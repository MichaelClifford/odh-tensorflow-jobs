apiVersion: v1
kind: Template
metadata:
  name: odh-tensorflow-training
  annotations:
    description: "Template to train models using tensorflow"
    openshift.io/display-name: "Tensorflow Training Job"
    iconClass: "icon-python"
    tags: "opendatahub,tensorflow"
    openshift.io/provider-display-name: "Open Data Hub"
  labels:
    template: odh-tensorlow-training
objects:
- apiVersion: batch/v1
  kind: Job
  metadata:
    name: odh-tensorflow-training-${APP_NAME}
    labels:
      app: ${APP_NAME}
      job: odh-tensorflow-training-${APP_NAME}
  spec:
    parallelism: 1    
    completions: 1    
    backoffLimit: 0
    template:         
      metadata:
        name: odh-tensorflow-training-${APP_NAME}
        labels:
          app: ${APP_NAME}
          job: odh-tensorflow-training-${APP_NAME}
      spec:
        restartPolicy: Never
        automountServiceAccountToken: false
        containers:
        - name: ${APP_NAME}
          image: odh-tensorflow-training
          env:
          - name: GIT_REPO
            value: ${GIT_REPO}
          - name: CONTEXT_DIR
            value: ${CONTEXT_DIR}
          - name: RUN_FILE
            value: ${RUN_FILE}
          - name: TRAINING_STEPS
            value: "${TRAINING_STEPS}"
          resources:
            limits:
              memory: '${MEMORY}'
              cpu: '${CPU}'

        restartPolicy: Never
    

parameters:
- name: APP_NAME
  description: Short name of your application (to be used in OpenShift artifact names)
  value: demo
  required: true
- name: TRAINING_STEPS
  description: Number of training steps to perform
  required: true
  value: "10000"
- name: INPUT_DATA_LOCATION
  description: "Location of input data in form of 's3://BUCKET/path/', path is used as prefix to lookup the data in S3"
  value: s3://MY-BUCKET/data/
  required: true
- name: OUTPUT_MODEL_LOCATION
  description: "Location where the resulting model will be stored"
  required: true
  value: s3://MY-BUCKET/model-out/
- name: S3_ENDPOINT_URL
  description: URL of S3 endpoint to be used for data storage
  required: true
  value: https://s3.upshift.redhat.com
- name: AWS_SECRET_ACCESS_KEY
  description: S3 instance secret access key
  required: true
- name: AWS_ACCESS_KEY_ID
  description: S3 instance access key id
  required: true
- name: MEMORY
  description: Memory limit to be assigned to the job
  value: 2Gi
  required: true
- name: CPU
  description: Limit for number of cores to assign to the job
  value: "2"
  required: true
- name: GIT_REPO
  description: Repository to build from
  value: https://github.com/vpavlin/odh-tensorflow-jobs
  required: true
- name: CONTEXT_DIR
  description: Directory inside the git repository to use as root
  value:
- name: RUN_FILE
  description: A file containing code doing the training
  default: training/app.py
